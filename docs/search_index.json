[["survival-analysis-intro.html", "Survival HW 1 1 Survival Analysis Intro", " Survival HW 1 2024-11-02 1 Survival Analysis Intro bucket_exists( bucket = &quot;s3://survival2024/&quot;, region = &quot;us-east-1&quot; ) ## [1] TRUE ## attr(,&quot;x-amz-id-2&quot;) ## [1] &quot;ejLhvt8IjWLi/t/pKMMh972nBz5Zt0YvpWesOuyW/We7oHOHxPvlsRhZh+k+PUtABTt1pkphtjs=&quot; ## attr(,&quot;x-amz-request-id&quot;) ## [1] &quot;JSKDE3WYKTX9A6VH&quot; ## attr(,&quot;date&quot;) ## [1] &quot;Fri, 10 Jan 2025 19:35:25 GMT&quot; ## attr(,&quot;x-amz-bucket-region&quot;) ## [1] &quot;us-east-1&quot; ## attr(,&quot;x-amz-access-point-alias&quot;) ## [1] &quot;false&quot; ## attr(,&quot;content-type&quot;) ## [1] &quot;application/xml&quot; ## attr(,&quot;transfer-encoding&quot;) ## [1] &quot;chunked&quot; ## attr(,&quot;server&quot;) ## [1] &quot;AmazonS3&quot; files &lt;- get_bucket_df( bucket = &quot;s3://survival2024/&quot;, region = &quot;us-east-1&quot;, max = 20000 ) %&gt;% as_tibble() #Downloading files save_object( object = &quot;hurricane.csv&quot;, #Change bucket = &quot;s3://survival2024/&quot;, region = &quot;us-east-1&quot;, file = &quot;hurricane&quot; #Change ) ## [1] &quot;hurricane&quot; #You can now start Wrangling the data... hurricane &lt;- read.csv(&quot;hurricane&quot;) #Change hurricane = hurricane %&gt;% dplyr::mutate(Index = row_number()) Give the percentage of pumps within each failure type and percentage of pumps that did not fail. # Frequency table for the REASON variable reason_counts &lt;- table(hurricane$reason) reason_counts ## ## 0 1 2 3 4 ## 316 115 112 111 116 # Total number of pumps total_pumps &lt;- sum(reason_counts) # Calculate percentages for each failure type reason_percentages &lt;- (reason_counts / total_pumps) * 100 reason_percentages ## ## 0 1 2 3 4 ## 41.03896 14.93506 14.54545 14.41558 15.06494 No failure: 41.03% Reason 1: 14.94% Reason 2: 14.55% Reason 3: 14.42% Reason 4: 15.06% Give the average time until failure for each failure type. Are means a good measure for length of survival? Discuss why or why not. # Calculate mean failure time for each failure type average_failure_time &lt;- aggregate(hurricane$hour, by = list(hurricane$reason), FUN = mean, na.rm = TRUE) # Rename columns for clarity colnames(average_failure_time) &lt;- c(&quot;Failure_Type&quot;, &quot;Average_Time_Until_Failure&quot;) # Print the results average_failure_time ## Failure_Type Average_Time_Until_Failure ## 1 0 48.00000 ## 2 1 26.44348 ## 3 2 41.04464 ## 4 3 38.82883 ## 5 4 21.93966 Reason 1: 26.44 hr Reason 2: 41.04 hr Reason 3: 38.83 hr Reason 4: 21.94 hr Means are not a good measure of length of survival because censored values included in the mean can impact the mean survival time. Median is a better measure. Create and upload the survival probability across time for pumps broken down by failure type overlaid into one graph. # Assuming the SURVIVE variable is coded as 1 for failed and 0 for not failed surv_object &lt;- Surv(time = hurricane$hour, event = hurricane$survive == 0) # Fit the Kaplan-Meier survival model, stratified by failure type (REASON) km_fit &lt;- survfit(surv_object ~ hurricane$reason, data = hurricane) # Plot survival curves with ggplot2 styling for readability surv_plot &lt;- ggsurvplot( km_fit, data = hurricane, conf.int = TRUE, legend.title = &quot;Failure Type&quot;, legend.labs = c(&quot;No Failure&quot;, &quot;Flood&quot;, &quot;Motor&quot;, &quot;Surge&quot;, &quot;Jammed&quot;), xlab = &quot;Time (hours)&quot;, ylab = &quot;Survival Probability&quot;, title = &quot;Survival Probability Across Time by Failure Type&quot;, ggtheme = theme_minimal() ) surv_plot Create and upload the graph of conditional failure probabilities across time for pumps broken down by failure type overlaid into one graph. km_fit &lt;- survfit(surv_object ~ hurricane$reason, data = hurricane) h = km_fit$n.event/km_fit$n.risk index.h=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0 index.h[(km_fit$time)+1]=h #Because of 0 haz.plot=data.frame(cbind(seq(0,max(hurricane$hour)), index.h)) colnames(haz.plot)=c(&quot;Time&quot;,&quot;Hazard&quot;) ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line() ggsurvplot(km_fit, data = hurricane, fun = &quot;cumhaz&quot;, conf.int = TRUE, xlab = &quot;Time (hour)&quot;, ylab = &quot;Cumulative Hazard&quot;, title = &quot;Conditional Failure Probabilities&quot;, legend.title = &quot;Failure Type&quot;, legend.labs = c(&quot;No Failure&quot;, &quot;Flood&quot;, &quot;Motor&quot;, &quot;Surge&quot;, &quot;Jammed&quot;)) surv_object &lt;- Surv(time = filter(hurricane, reason==1)$hour, event = filter(hurricane, reason==1)$survive == 0) km_fit &lt;- survfit(surv_object ~ 1, data = filter(hurricane, reason==1)) h1 = km_fit$n.event/km_fit$n.risk index.h1=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0 index.h1[(km_fit$time)+1]=h1 #Because of 0 haz.plot1=data.frame(cbind(seq(0,max(hurricane$hour)), index.h1)) haz.plot1$Reason1 = 1 surv_object &lt;- Surv(time = filter(hurricane, reason==2)$hour, event = filter(hurricane, reason==2)$survive == 0) km_fit &lt;- survfit(surv_object ~ 1, data = filter(hurricane, reason==2)) h2 = km_fit$n.event/km_fit$n.risk index.h2=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0 index.h2[(km_fit$time)+1]=h2 #Because of 0 haz.plot2=data.frame(cbind(seq(0,max(hurricane$hour)), index.h2)) haz.plot2$Reason2 = 2 surv_object &lt;- Surv(time = filter(hurricane, reason==3)$hour, event = filter(hurricane, reason==3)$survive == 0) km_fit &lt;- survfit(surv_object ~ 1, data = filter(hurricane, reason==3)) h3 = km_fit$n.event/km_fit$n.risk index.h3=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0 index.h3[(km_fit$time)+1]=h3 #Because of 0 haz.plot3=data.frame(cbind(seq(0,max(hurricane$hour)), index.h3)) haz.plot3$Reason3 = 3 surv_object &lt;- Surv(time = filter(hurricane, reason==4)$hour, event = filter(hurricane, reason==4)$survive == 0) km_fit &lt;- survfit(surv_object ~ 1, data = filter(hurricane, reason==4)) h4 = km_fit$n.event/km_fit$n.risk index.h4=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0 index.h4[(km_fit$time)+1]=h4 #Because of 0 haz.plot4=data.frame(cbind(seq(0,max(hurricane$hour)), index.h4)) haz.plot4$Reason4 = 4 haz.plot.all = cbind(haz.plot1, haz.plot2, haz.plot3, haz.plot4) haz.plot.all2 = haz.plot.all %&gt;% dplyr::select(1, index.h1, index.h2, index.h3, index.h4) ggplot(haz.plot.all2, aes(x=V1)) + geom_line(aes(y = index.h1, color=&#39;Flood&#39;)) + geom_line(aes(y = index.h2, color=&#39;Motor&#39;)) + geom_line(aes(y = index.h3, color = &#39;Surge&#39;)) + geom_line(aes(y = index.h4, color= &#39;Jammed&#39;)) + labs( title = &quot;Hazard Rates by Failure Type&quot;, x = &quot;Hours&quot;, y = &quot;Hazard&quot;, color = &quot;Failure Type&quot; ) + scale_color_manual( values = c(&#39;Flood&#39; = &#39;blue&#39;, &#39;Motor&#39; = &#39;red&#39;, &#39;Surge&#39; = &#39;orange&#39;, &#39;Jammed&#39; = &#39;green&#39;), labels = c(&quot;Flood&quot;, &quot;Motor&quot;, &quot;Surge&quot;, &quot;Jammed&quot;)) + theme_minimal() + scale_x_continuous(breaks = seq(0, 48, by = 6)) Provide a statistical test to see if the major types of failure have similar survival probabilities across time (include null and alternative hypotheses, test statistic, p-value and conclusion). # Log-Rank Test surv_object &lt;- Surv(time = hurricane$hour, event = hurricane$survive == 0) survdiff(surv_object ~ hurricane$reason, data=hurricane,rho=0) ## Call: ## survdiff(formula = surv_object ~ hurricane$reason, data = hurricane, ## rho = 0) ## ## N Observed Expected (O-E)^2/E (O-E)^2/V ## hurricane$reason=0 316 0 275.1 275.1 797.8 ## hurricane$reason=1 115 115 32.2 213.5 242.4 ## hurricane$reason=2 112 112 68.0 28.4 35.1 ## hurricane$reason=3 111 111 55.6 55.2 66.0 ## hurricane$reason=4 116 116 23.1 373.8 435.3 ## ## Chisq= 1120 on 4 degrees of freedom, p= &lt;2e-16 Log-Rank Test: H0: No significant difference in survival probabilities. Ha: Significant difference in survival probabilities. Test statistic: 1120 on 4 degrees of freedom p-value: &lt;2e-16 Conclusion: Reject the null -&gt; There is a significant difference in survival probabilities over time across failure types. "],["accelerated-failure-time-model.html", " 2 Accelerated Failure Time Model", " 2 Accelerated Failure Time Model ##Model Building hurricane = hurricane %&gt;% mutate(flood = ifelse(reason==1, 1, 0)) hurr.aft.w &lt;- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;weibull&quot;) plot(hurr.aft.w, type = &quot;cumhaz&quot;, ci = TRUE, conf.int = FALSE, las = 1, bty = &quot;n&quot;, xlab = &quot;week&quot;, ylab = &quot;Cumulative Hazard&quot;, main = &quot;Weibull Distribution&quot;) hurr.aft.e &lt;- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;exp&quot;) plot(hurr.aft.e, type = &quot;cumhaz&quot;, ci = TRUE, conf.int = FALSE, las = 1, bty = &quot;n&quot;, xlab = &quot;week&quot;, ylab = &quot;Cumulative Hazard&quot;, main = &quot;Exponential Distribution&quot;) hurr.aft.g &lt;- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;gamma&quot;) plot(hurr.aft.g, type = &quot;cumhaz&quot;, ci = TRUE, conf.int = FALSE, las = 1, bty = &quot;n&quot;, xlab = &quot;week&quot;, ylab = &quot;Cumulative Hazard&quot;, main = &quot;Gamma Distribution&quot;) hurr.aft.ll &lt;- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;llogis&quot;) plot(hurr.aft.ll, type = &quot;cumhaz&quot;, ci = TRUE, conf.int = FALSE, las = 1, bty = &quot;n&quot;, xlab = &quot;week&quot;, ylab = &quot;Cumulative Hazard&quot;, main = &quot;Log-Logistic Distribution&quot;) hurr.aft.ln &lt;- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;lognormal&quot;) plot(hurr.aft.ln, type = &quot;cumhaz&quot;, ci = TRUE, conf.int = FALSE, las = 1, bty = &quot;n&quot;, xlab = &quot;week&quot;, ylab = &quot;Cumulative Hazard&quot;, main = &quot;Log-Normal Distribution&quot;) ##Goodness-of-Fit Tests like.e = flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;exp&quot;)$loglik like.w &lt;- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;weibull&quot;)$loglik like.ln &lt;- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;lnorm&quot;)$loglik like.g = flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;gamma&quot;)$loglik like.ll = flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;llogis&quot;)$loglik like.f = flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;genf&quot;)$loglik pval.e.g = pchisq((-2*(like.e-like.g)), 2,lower.tail=F) pval.w.g = pchisq((-2*(like.w-like.g)), 1,lower.tail=F) pval.ln.g = pchisq((-2*(like.ln-like.g)), 1,lower.tail=F) ##pval.g.f = pchisq((-2*(like.g-like.f)), 1,lower.tail=F) Tests = c(&#39;Exp vs. Gam&#39;, &#39;Wei vs. Gam&#39;, &#39;LogN vs. Gam&#39;) P_values = c(pval.e.g, pval.w.g, pval.ln.g) cbind(Tests, P_values) ## Tests P_values ## [1,] &quot;Exp vs. Gam&quot; &quot;1.15756879954454e-05&quot; ## [2,] &quot;Wei vs. Gam&quot; &quot;1&quot; ## [3,] &quot;LogN vs. Gam&quot; &quot;0.0113749320431249&quot; No difference between Weibull and Gam -&gt; use Weibull ##Variable Selection full.model &lt;- survreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = &quot;weibull&quot;) empty.model &lt;- survreg(Surv(hour, flood) ~ 1, data = hurricane, dist = &quot;weibull&quot;) back.model &lt;- step(full.model, scope = list(lower = empty.model, upper = full.model), direction = &#39;backward&#39;, k = qchisq(0.03, 1, lower.tail=FALSE)) ## Start: AIC=1496.55 ## Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + ## trashrack + slope + elevation ## ## Df AIC ## - elevation 1 1492.3 ## - age 1 1492.4 ## - bridgecrane 1 1492.8 ## - gear 1 1494.8 ## - servo 1 1495.6 ## - trashrack 1 1495.8 ## - backup 1 1495.9 ## &lt;none&gt; 1496.5 ## - slope 1 1502.5 ## ## Step: AIC=1492.31 ## Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + ## trashrack + slope ## ## Df AIC ## - age 1 1488.1 ## - bridgecrane 1 1488.5 ## - gear 1 1490.5 ## - trashrack 1 1491.7 ## - servo 1 1491.7 ## - backup 1 1491.8 ## &lt;none&gt; 1492.3 ## - slope 1 1499.2 ## ## Step: AIC=1488.11 ## Surv(hour, flood) ~ backup + bridgecrane + servo + gear + trashrack + ## slope ## ## Df AIC ## - bridgecrane 1 1484.2 ## - gear 1 1486.5 ## - trashrack 1 1487.3 ## - backup 1 1488.1 ## &lt;none&gt; 1488.1 ## - servo 1 1488.9 ## - slope 1 1495.0 ## ## Step: AIC=1484.21 ## Surv(hour, flood) ~ backup + servo + gear + trashrack + slope ## ## Df AIC ## - gear 1 1483.0 ## - trashrack 1 1483.5 ## - backup 1 1483.9 ## &lt;none&gt; 1484.2 ## - servo 1 1485.2 ## - slope 1 1490.9 ## ## Step: AIC=1482.97 ## Surv(hour, flood) ~ backup + servo + trashrack + slope ## ## Df AIC ## - trashrack 1 1481.9 ## - backup 1 1482.5 ## &lt;none&gt; 1483.0 ## - servo 1 1487.7 ## - slope 1 1488.9 ## ## Step: AIC=1481.88 ## Surv(hour, flood) ~ backup + servo + slope ## ## Df AIC ## &lt;none&gt; 1481.9 ## - backup 1 1482.2 ## - servo 1 1486.4 ## - slope 1 1487.8 hurr.aft = survreg(Surv(hour, flood) ~ backup + servo + slope, data = hurricane, dist = &quot;weibull&quot;) summary(hurr.aft) ## ## Call: ## survreg(formula = Surv(hour, flood) ~ backup + servo + slope, ## data = hurricane, dist = &quot;weibull&quot;) ## Value Std. Error z p ## (Intercept) 4.7711 0.1524 31.31 &lt; 2e-16 ## backup 0.2710 0.1236 2.19 0.02831 ## servo 0.3859 0.1306 2.95 0.00313 ## slope -0.0606 0.0174 -3.47 0.00051 ## Log(scale) -0.4381 0.0860 -5.10 3.5e-07 ## ## Scale= 0.645 ## ## Weibull distribution ## Loglik(model)= -729.2 Loglik(intercept only)= -744.8 ## Chisq= 31.21 on 3 degrees of freedom, p= 7.7e-07 ## Number of Newton-Raphson Iterations: 7 ## n= 770 survprob.75.50.25 = predict(hurr.aft, type = &quot;quantile&quot;, se.fit = TRUE,p = c(0.25, 0.5, 0.75)) head(survprob.75.50.25$fit) ## [,1] [,2] [,3] ## [1,] 44.05062 77.69575 121.52050 ## [2,] 34.56747 60.96954 95.35976 ## [3,] 44.05062 77.69575 121.52050 ## [4,] 54.36369 95.88577 149.97070 ## [5,] 64.79470 114.28381 178.74628 ## [6,] 69.27767 122.19080 191.11324 exp(coef(hurr.aft)) - 1 ## (Intercept) backup servo slope ## 117.05233813 0.31122730 0.47091467 -0.05880652 ##Variable Impact hurricane = hurricane %&gt;% dplyr::mutate(pump = row_number()) #Servo impact survprob.actual = 1 - psurvreg(hurricane$hour, mean = predict(hurr.aft, type = &quot;lp&quot;), scale = hurr.aft$scale, distribution = hurr.aft$dist) new_time = qsurvreg(1 - survprob.actual, mean = predict(hurr.aft, type = &quot;lp&quot;) + coef(hurr.aft)[&#39;servo&#39;], scale = hurr.aft$scale, distribution = hurr.aft$dist) hurricane$new_time = new_time hurricane$diff = hurricane$new_time - hurricane$hour impact.servo=data.frame(hurricane$hour, hurricane$new_time, hurricane$diff, hurricane$flood, hurricane$servo, hurricane$pump) colnames(impact.servo)=c(&quot;O.hour&quot;,&quot;N.hour&quot;,&quot;Diff_servo&quot;,&quot;flood&quot;,&quot;servo&quot;, &quot;pump&quot;) impact.servo=subset(impact.servo,flood==1 &amp; servo==0) impact.servo %&gt;% arrange(desc(Diff_servo)) %&gt;% filter(O.hour &lt;48 &amp; N.hour &gt;48) ## O.hour N.hour Diff_servo flood servo pump ## 1 45 66.19116 21.19116 1 0 375 ## 2 44 64.72025 20.72025 1 0 339 ## 3 43 63.24933 20.24933 1 0 357 ## 4 42 61.77842 19.77842 1 0 331 ## 5 42 61.77842 19.77842 1 0 366 ## 6 42 61.77842 19.77842 1 0 370 ## 7 42 61.77842 19.77842 1 0 394 ## 8 40 58.83659 18.83659 1 0 342 ## 9 40 58.83659 18.83659 1 0 380 ## 10 37 54.42384 17.42384 1 0 317 ## 11 37 54.42384 17.42384 1 0 358 ## 12 36 52.95293 16.95293 1 0 419 ## 13 35 51.48201 16.48201 1 0 364 ## 14 34 50.01110 16.01110 1 0 417 ## 15 33 48.54018 15.54018 1 0 318 ## 16 33 48.54018 15.54018 1 0 397 ## 17 33 48.54018 15.54018 1 0 343 testing = impact.servo %&gt;% arrange(desc(Diff_servo)) %&gt;% filter(N.hour &lt; 49 &amp; N.hour &gt;33) testing ## O.hour N.hour Diff_servo flood servo pump ## 1 33 48.54018 15.54018 1 0 318 ## 2 33 48.54018 15.54018 1 0 397 ## 3 33 48.54018 15.54018 1 0 343 ## 4 32 47.06927 15.06927 1 0 329 ## 5 32 47.06927 15.06927 1 0 347 ## 6 31 45.59835 14.59835 1 0 350 ## 7 31 45.59835 14.59835 1 0 410 ## 8 30 44.12744 14.12744 1 0 352 ## 9 30 44.12744 14.12744 1 0 367 ## 10 30 44.12744 14.12744 1 0 369 ## 11 30 44.12744 14.12744 1 0 376 ## 12 28 41.18561 13.18561 1 0 319 ## 13 26 38.24378 12.24378 1 0 321 ## 14 25 36.77287 11.77287 1 0 404 ## 15 25 36.77287 11.77287 1 0 408 ## 16 24 35.30195 11.30195 1 0 399 ## 17 23 33.83104 10.83104 1 0 377 ## 18 23 33.83104 10.83104 1 0 403 #Backup impact survprob.actual = 1 - psurvreg(hurricane$hour, mean = predict(hurr.aft, type = &quot;lp&quot;), scale = hurr.aft$scale, distribution = hurr.aft$dist) head(survprob.actual, n = 10) ## [1] 0.7199136 0.6197293 0.7199136 0.7888291 0.8346742 0.8496614 0.7414375 0.6468896 0.7615909 ## [10] 0.7414375 new_time = qsurvreg(1 - survprob.actual, mean = predict(hurr.aft, type = &quot;lp&quot;) + coef(hurr.aft)[&#39;backup&#39;], scale = hurr.aft$scale, distribution = hurr.aft$dist) hurricane$new_time = new_time hurricane$diff = hurricane$new_time - hurricane$hour impact.backup=data.frame(hurricane$hour, hurricane$new_time, hurricane$diff, hurricane$flood, hurricane$backup, hurricane$pump) colnames(impact.backup)=c(&quot;O.hour&quot;,&quot;N.hour&quot;,&quot;Diff_backup&quot;,&quot;flood&quot;,&quot;backup&quot;, &quot;pump&quot;) impact.backup=subset(impact.backup,flood==1 &amp; backup==0) impact.backup %&gt;% arrange(desc(Diff_backup)) %&gt;% filter(N.hour &gt;48) ## O.hour N.hour Diff_backup flood backup pump ## 1 48 62.93891 14.93891 1 0 361 ## 2 48 62.93891 14.93891 1 0 389 ## 3 48 62.93891 14.93891 1 0 392 ## 4 48 62.93891 14.93891 1 0 426 ## 5 46 60.31646 14.31646 1 0 373 ## 6 45 59.00523 14.00523 1 0 387 ## 7 45 59.00523 14.00523 1 0 423 ## 8 44 57.69400 13.69400 1 0 339 ## 9 43 56.38277 13.38277 1 0 357 ## 10 42 55.07155 13.07155 1 0 366 ## 11 42 55.07155 13.07155 1 0 370 ## 12 41 53.76032 12.76032 1 0 345 ## 13 41 53.76032 12.76032 1 0 349 ## 14 40 52.44909 12.44909 1 0 337 ## 15 40 52.44909 12.44909 1 0 342 ## 16 40 52.44909 12.44909 1 0 372 ## 17 40 52.44909 12.44909 1 0 380 ## 18 37 48.51541 11.51541 1 0 317 ## 19 37 48.51541 11.51541 1 0 324 ## 20 37 48.51541 11.51541 1 0 333 testing2 = impact.backup %&gt;% arrange(desc(Diff_backup)) %&gt;% filter(N.hour &lt; 49 &amp; N.hour &gt;33) testing2 ## O.hour N.hour Diff_backup flood backup pump ## 1 37 48.51541 11.515410 1 0 317 ## 2 37 48.51541 11.515410 1 0 324 ## 3 37 48.51541 11.515410 1 0 333 ## 4 36 47.20418 11.204183 1 0 395 ## 5 35 45.89296 10.892955 1 0 364 ## 6 34 44.58173 10.581728 1 0 322 ## 7 34 44.58173 10.581728 1 0 427 ## 8 32 41.95927 9.959274 1 0 325 ## 9 30 39.33682 9.336819 1 0 367 ## 10 30 39.33682 9.336819 1 0 369 ## 11 30 39.33682 9.336819 1 0 376 ## 12 29 38.02559 9.025592 1 0 359 ## 13 28 36.71436 8.714364 1 0 319 ## 14 26 34.09191 8.091910 1 0 321 ## 15 26 34.09191 8.091910 1 0 374 list1 &lt;- testing$pump list2 &lt;- testing2$pump # Find items in list1 that are not in list2 not_in_list2 &lt;- list1[list1 %in% list2] print(not_in_list2) ## [1] 367 369 376 319 321 367, 369, 376, 319, 321 all inc more with Servo upgrades = merge(impact.servo, impact.backup, by=&quot;pump&quot;, all=TRUE) %&gt;% dplyr::select(Diff_servo, Diff_backup, pump) upgrades[is.na(upgrades)] &lt;- 0 upgrades = upgrades %&gt;% mutate(servo_impact = 150000/Diff_servo, backup_impact = 100000/Diff_backup, better = ifelse(backup_impact &gt; servo_impact, 1, 0)) upgrades %&gt;% arrange(desc(Diff_servo)) ## Diff_servo Diff_backup pump servo_impact backup_impact better ## 1 22.6039042 14.9389103 361 6636.022 6693.929 1 ## 2 21.1911602 0.0000000 375 7078.423 Inf 1 ## 3 20.7202455 13.6940011 339 7239.296 7302.468 1 ## 4 20.2493308 13.3827738 357 7407.652 7472.292 1 ## 5 19.7784162 0.0000000 331 7584.025 Inf 1 ## 6 19.7784162 13.0715465 366 7584.025 7650.204 1 ## 7 19.7784162 13.0715465 370 7584.025 7650.204 1 ## 8 19.7784162 0.0000000 394 7584.025 Inf 1 ## 9 18.8365868 12.4490919 342 7963.226 8032.714 1 ## 10 18.8365868 12.4490919 380 7963.226 8032.714 1 ## 11 17.4238428 11.5154100 317 8608.893 8684.016 1 ## 12 17.4238428 0.0000000 358 8608.893 Inf 1 ## 13 16.9529282 0.0000000 419 8848.029 Inf 1 ## 14 16.4820135 10.8929554 364 9100.830 9180.245 1 ## 15 16.0110988 0.0000000 417 9368.501 Inf 1 ## 16 15.5401841 0.0000000 318 9652.395 Inf 1 ## 17 15.5401841 0.0000000 397 9652.395 Inf 1 ## 18 15.5401841 0.0000000 343 9652.395 Inf 1 ## 19 15.0692695 0.0000000 329 9954.033 Inf 1 ## 20 15.0692695 0.0000000 347 9954.033 Inf 1 ## 21 14.5983548 0.0000000 350 10275.130 Inf 1 ## 22 14.5983548 0.0000000 410 10275.130 Inf 1 ## 23 14.1274401 0.0000000 352 10617.635 Inf 1 ## 24 14.1274401 9.3368189 367 10617.635 10710.286 1 ## 25 14.1274401 9.3368189 369 10617.635 10710.286 1 ## 26 14.1274401 9.3368189 376 10617.635 10710.286 1 ## 27 13.1856108 8.7143643 319 11376.037 11475.306 1 ## 28 12.2437814 8.0919097 321 12251.117 12358.022 1 ## 29 11.7728668 7.7806824 404 12741.162 12852.343 1 ## 30 11.7728668 7.7806824 408 12741.162 12852.343 1 ## 31 11.3019521 7.4694551 399 13272.044 13387.857 1 ## 32 10.8310374 7.1582278 377 13849.089 13969.938 1 ## 33 10.8310374 7.1582278 403 13849.089 13969.938 1 ## 34 9.4182934 0.0000000 368 15926.452 Inf 1 ## 35 8.9473787 5.9133186 416 16764.687 16910.978 1 ## 36 8.4764641 0.0000000 353 17696.058 Inf 1 ## 37 8.4764641 0.0000000 384 17696.058 Inf 1 ## 38 8.4764641 0.0000000 406 17696.058 Inf 1 ## 39 8.4764641 5.6020913 346 17696.058 17850.477 1 ## 40 8.4764641 5.6020913 412 17696.058 17850.477 1 ## 41 8.0055494 0.0000000 336 18737.003 Inf 1 ## 42 8.0055494 5.2908640 365 18737.003 18900.505 1 ## 43 7.5346347 4.9796368 340 19908.065 20081.786 1 ## 44 7.5346347 4.9796368 341 19908.065 20081.786 1 ## 45 7.5346347 4.9796368 363 19908.065 20081.786 1 ## 46 7.0637201 4.6684095 428 21235.270 21420.572 1 ## 47 7.0637201 0.0000000 405 21235.270 Inf 1 ## 48 6.5928054 0.0000000 330 22752.075 Inf 1 ## 49 6.5928054 0.0000000 385 22752.075 Inf 1 ## 50 6.1218907 4.0459549 360 24502.234 24716.044 1 ## 51 6.1218907 4.0459549 398 24502.234 24716.044 1 ## 52 5.6509761 3.7347276 401 26544.087 26775.715 1 ## 53 4.7091467 0.0000000 320 31852.904 Inf 1 ## 54 4.7091467 3.1122730 356 31852.904 32130.858 1 ## 55 4.2382320 2.8010457 390 35392.116 35700.953 1 ## 56 3.7673174 0.0000000 424 39816.131 Inf 1 ## 57 3.2964027 0.0000000 383 45504.149 Inf 1 ## 58 3.2964027 2.1785911 381 45504.149 45901.225 1 ## 59 2.8254880 0.0000000 327 53088.174 Inf 1 ## 60 2.8254880 1.8673638 328 53088.174 53551.430 1 ## 61 2.3545734 1.5561365 355 63705.809 64261.715 1 ## 62 1.4127440 0.9336819 418 106176.348 107102.859 1 ## 63 0.4709147 0.3112273 382 318529.044 321308.577 1 ## 64 0.0000000 10.5817281 322 Inf 9450.252 0 ## 65 0.0000000 7.1582278 323 Inf 13969.938 0 ## 66 0.0000000 11.5154100 324 Inf 8684.016 0 ## 67 0.0000000 9.9592735 325 Inf 10040.893 0 ## 68 0.0000000 1.2449092 332 Inf 80327.144 0 ## 69 0.0000000 11.5154100 333 Inf 8684.016 0 ## 70 0.0000000 12.4490919 337 Inf 8032.714 0 ## 71 0.0000000 12.7603192 345 Inf 7836.795 0 ## 72 0.0000000 12.7603192 349 Inf 7836.795 0 ## 73 0.0000000 9.0255916 359 Inf 11079.606 0 ## 74 0.0000000 12.4490919 372 Inf 8032.714 0 ## 75 0.0000000 14.3164557 373 Inf 6984.969 0 ## 76 0.0000000 8.0919097 374 Inf 12358.022 0 ## 77 0.0000000 7.7806824 379 Inf 12852.343 0 ## 78 0.0000000 5.2908640 386 Inf 18900.505 0 ## 79 0.0000000 14.0052284 387 Inf 7140.191 0 ## 80 0.0000000 14.9389103 389 Inf 6693.929 0 ## 81 0.0000000 14.9389103 392 Inf 6693.929 0 ## 82 0.0000000 7.4694551 393 Inf 13387.857 0 ## 83 0.0000000 11.2041827 395 Inf 8925.238 0 ## 84 0.0000000 6.8470005 407 Inf 14604.935 0 ## 85 0.0000000 5.9133186 409 Inf 16910.978 0 ## 86 0.0000000 6.5357732 411 Inf 15300.408 0 ## 87 0.0000000 2.1785911 420 Inf 45901.225 0 ## 88 0.0000000 14.0052284 423 Inf 7140.191 0 ## 89 0.0000000 7.4694551 425 Inf 13387.857 0 ## 90 0.0000000 14.9389103 426 Inf 6693.929 0 ## 91 0.0000000 10.5817281 427 Inf 9450.252 0 ## 92 0.0000000 6.8470005 430 Inf 14604.935 0 ## 93 0.0000000 0.6224546 431 Inf 160654.289 0 upgrades %&gt;% arrange(desc(Diff_backup)) ## Diff_servo Diff_backup pump servo_impact backup_impact better ## 1 22.6039042 14.9389103 361 6636.022 6693.929 1 ## 2 0.0000000 14.9389103 389 Inf 6693.929 0 ## 3 0.0000000 14.9389103 392 Inf 6693.929 0 ## 4 0.0000000 14.9389103 426 Inf 6693.929 0 ## 5 0.0000000 14.3164557 373 Inf 6984.969 0 ## 6 0.0000000 14.0052284 387 Inf 7140.191 0 ## 7 0.0000000 14.0052284 423 Inf 7140.191 0 ## 8 20.7202455 13.6940011 339 7239.296 7302.468 1 ## 9 20.2493308 13.3827738 357 7407.652 7472.292 1 ## 10 19.7784162 13.0715465 366 7584.025 7650.204 1 ## 11 19.7784162 13.0715465 370 7584.025 7650.204 1 ## 12 0.0000000 12.7603192 345 Inf 7836.795 0 ## 13 0.0000000 12.7603192 349 Inf 7836.795 0 ## 14 0.0000000 12.4490919 337 Inf 8032.714 0 ## 15 18.8365868 12.4490919 342 7963.226 8032.714 1 ## 16 0.0000000 12.4490919 372 Inf 8032.714 0 ## 17 18.8365868 12.4490919 380 7963.226 8032.714 1 ## 18 17.4238428 11.5154100 317 8608.893 8684.016 1 ## 19 0.0000000 11.5154100 324 Inf 8684.016 0 ## 20 0.0000000 11.5154100 333 Inf 8684.016 0 ## 21 0.0000000 11.2041827 395 Inf 8925.238 0 ## 22 16.4820135 10.8929554 364 9100.830 9180.245 1 ## 23 0.0000000 10.5817281 322 Inf 9450.252 0 ## 24 0.0000000 10.5817281 427 Inf 9450.252 0 ## 25 0.0000000 9.9592735 325 Inf 10040.893 0 ## 26 14.1274401 9.3368189 367 10617.635 10710.286 1 ## 27 14.1274401 9.3368189 369 10617.635 10710.286 1 ## 28 14.1274401 9.3368189 376 10617.635 10710.286 1 ## 29 0.0000000 9.0255916 359 Inf 11079.606 0 ## 30 13.1856108 8.7143643 319 11376.037 11475.306 1 ## 31 12.2437814 8.0919097 321 12251.117 12358.022 1 ## 32 0.0000000 8.0919097 374 Inf 12358.022 0 ## 33 11.7728668 7.7806824 408 12741.162 12852.343 1 ## 34 0.0000000 7.7806824 379 Inf 12852.343 0 ## 35 11.7728668 7.7806824 404 12741.162 12852.343 1 ## 36 11.3019521 7.4694551 399 13272.044 13387.857 1 ## 37 0.0000000 7.4694551 425 Inf 13387.857 0 ## 38 0.0000000 7.4694551 393 Inf 13387.857 0 ## 39 10.8310374 7.1582278 377 13849.089 13969.938 1 ## 40 0.0000000 7.1582278 323 Inf 13969.938 0 ## 41 10.8310374 7.1582278 403 13849.089 13969.938 1 ## 42 0.0000000 6.8470005 430 Inf 14604.935 0 ## 43 0.0000000 6.8470005 407 Inf 14604.935 0 ## 44 0.0000000 6.5357732 411 Inf 15300.408 0 ## 45 8.9473787 5.9133186 416 16764.687 16910.978 1 ## 46 0.0000000 5.9133186 409 Inf 16910.978 0 ## 47 8.4764641 5.6020913 346 17696.058 17850.477 1 ## 48 8.4764641 5.6020913 412 17696.058 17850.477 1 ## 49 0.0000000 5.2908640 386 Inf 18900.505 0 ## 50 8.0055494 5.2908640 365 18737.003 18900.505 1 ## 51 7.5346347 4.9796368 340 19908.065 20081.786 1 ## 52 7.5346347 4.9796368 341 19908.065 20081.786 1 ## 53 7.5346347 4.9796368 363 19908.065 20081.786 1 ## 54 7.0637201 4.6684095 428 21235.270 21420.572 1 ## 55 6.1218907 4.0459549 360 24502.234 24716.044 1 ## 56 6.1218907 4.0459549 398 24502.234 24716.044 1 ## 57 5.6509761 3.7347276 401 26544.087 26775.715 1 ## 58 4.7091467 3.1122730 356 31852.904 32130.858 1 ## 59 4.2382320 2.8010457 390 35392.116 35700.953 1 ## 60 0.0000000 2.1785911 420 Inf 45901.225 0 ## 61 3.2964027 2.1785911 381 45504.149 45901.225 1 ## 62 2.8254880 1.8673638 328 53088.174 53551.430 1 ## 63 2.3545734 1.5561365 355 63705.809 64261.715 1 ## 64 0.0000000 1.2449092 332 Inf 80327.144 0 ## 65 1.4127440 0.9336819 418 106176.348 107102.859 1 ## 66 0.0000000 0.6224546 431 Inf 160654.289 0 ## 67 0.4709147 0.3112273 382 318529.044 321308.577 1 ## 68 15.5401841 0.0000000 318 9652.395 Inf 1 ## 69 4.7091467 0.0000000 320 31852.904 Inf 1 ## 70 2.8254880 0.0000000 327 53088.174 Inf 1 ## 71 15.0692695 0.0000000 329 9954.033 Inf 1 ## 72 6.5928054 0.0000000 330 22752.075 Inf 1 ## 73 19.7784162 0.0000000 331 7584.025 Inf 1 ## 74 8.0055494 0.0000000 336 18737.003 Inf 1 ## 75 15.5401841 0.0000000 343 9652.395 Inf 1 ## 76 15.0692695 0.0000000 347 9954.033 Inf 1 ## 77 14.5983548 0.0000000 350 10275.130 Inf 1 ## 78 14.1274401 0.0000000 352 10617.635 Inf 1 ## 79 8.4764641 0.0000000 353 17696.058 Inf 1 ## 80 17.4238428 0.0000000 358 8608.893 Inf 1 ## 81 9.4182934 0.0000000 368 15926.452 Inf 1 ## 82 21.1911602 0.0000000 375 7078.423 Inf 1 ## 83 3.2964027 0.0000000 383 45504.149 Inf 1 ## 84 8.4764641 0.0000000 384 17696.058 Inf 1 ## 85 6.5928054 0.0000000 385 22752.075 Inf 1 ## 86 19.7784162 0.0000000 394 7584.025 Inf 1 ## 87 15.5401841 0.0000000 397 9652.395 Inf 1 ## 88 7.0637201 0.0000000 405 21235.270 Inf 1 ## 89 8.4764641 0.0000000 406 17696.058 Inf 1 ## 90 14.5983548 0.0000000 410 10275.130 Inf 1 ## 91 16.0110988 0.0000000 417 9368.501 Inf 1 ## 92 16.9529282 0.0000000 419 8848.029 Inf 1 ## 93 3.7673174 0.0000000 424 39816.131 Inf 1 library(aws.s3) library(tidyverse) library(survival) library(foreign) library(ggplot2) library(survminer) #library(rms) library(flexsurv) library(dplyr) library(ciTools) library(here) library(visreg) library(cmprsk) library(reticulate) "],["cox-proportional-hazard-model.html", " 3 Cox Proportional Hazard Model 3.1 Initial Variable Screening 3.2 Linearity Assumption 3.3 Time Dependency Assumption 3.4 Model Building and Evaluation", " 3 Cox Proportional Hazard Model ##Data Setup bucket_exists( bucket = &quot;s3://survival2024/&quot;, region = &quot;us-east-1&quot; ) ## [1] TRUE ## attr(,&quot;x-amz-id-2&quot;) ## [1] &quot;2lCIj4+Ct38nl3CgXR5/3YViV9OgI10oP6S6MrYRBDeMsu0XzFSCMC8V2ytEwVlOJuDqKOlsicA=&quot; ## attr(,&quot;x-amz-request-id&quot;) ## [1] &quot;VR6ASH0XX8K13RYP&quot; ## attr(,&quot;date&quot;) ## [1] &quot;Fri, 10 Jan 2025 19:35:28 GMT&quot; ## attr(,&quot;x-amz-bucket-region&quot;) ## [1] &quot;us-east-1&quot; ## attr(,&quot;x-amz-access-point-alias&quot;) ## [1] &quot;false&quot; ## attr(,&quot;content-type&quot;) ## [1] &quot;application/xml&quot; ## attr(,&quot;transfer-encoding&quot;) ## [1] &quot;chunked&quot; ## attr(,&quot;server&quot;) ## [1] &quot;AmazonS3&quot; files &lt;- get_bucket_df( bucket = &quot;s3://survival2024/&quot;, region = &quot;us-east-1&quot;, max = 20000 ) %&gt;% as_tibble() #Downloading files save_object( object = &quot;hurricane.csv&quot;, #Change bucket = &quot;s3://survival2024/&quot;, region = &quot;us-east-1&quot;, file = &quot;hurricane&quot; #Change ) ## [1] &quot;hurricane&quot; #You can now start Wrangling the data... hurricane &lt;- read.csv(&quot;hurricane&quot;) #Change # Rename hour so that the pivot does not take it in hurricane &lt;- hurricane %&gt;% dplyr::rename(&quot;censor&quot; = hour) # Add id column hurricane &lt;- hurricane %&gt;% mutate(id = 1:nrow(hurricane)) %&gt;% dplyr::select(id,everything()) # Pivot the hour columns hurrLong &lt;- hurricane %&gt;% pivot_longer( cols = starts_with(&quot;h&quot;), names_to = &quot;hour&quot;, values_to = &quot;pumpOn&quot; ) # Fixing hour column to be numeric instead of &quot;h1&quot; hurrLong &lt;- hurrLong %&gt;% mutate(hour = as.numeric(gsub(&quot;h&quot;,&quot;&quot;,hour))) # Initializing DF hurricaneLong &lt;- data.frame() ### Fixes reason, adds consecHour for(i in 1:nrow(hurricane)) { # Go id by id table = hurrLong %&gt;% filter(id == i) # Reduce rows to only include non-failed hours failedAt = as.numeric(table[1,&quot;censor&quot;]) table = table[1:failedAt,] # Set reason to 0 everywhere but the last hour if (table[1,&quot;reason&quot;] != 0){ reason = as.numeric(table[1,&quot;reason&quot;]) table$reason = 0 table[nrow(table),&quot;reason&quot;] = reason } # Test to see if the last 12 rows of PumpOn are 1, then set consecHour to 1 table = table %&gt;% mutate(consecHour = 0) for (j in 1:nrow(table)){ # Skip first 12 rows if (j &lt; 13){ next } # Set it to 1 man if (sum(table[(j-11):j,&quot;pumpOn&quot;],na.rm = T) == 12){ table[j,&quot;consecHour&quot;] &lt;- 1 } } # Bind that data frame!!!! hurricaneLong &lt;- bind_rows(hurricaneLong,table) } 3.1 Initial Variable Screening #hurricane &lt;- hurricane[,-(9:56)] #hurricane &lt;- hurricane %&gt;% dplyr::select(-survive,-reason2,-trashrack) # Backward stepping full.model &lt;- coxph(Surv(censor, reason == 2) ~ backup + age + bridgecrane + servo + gear + slope + elevation, data = hurricane) empty.model &lt;- coxph(Surv(censor, reason == 2) ~ 1, data = hurricane) back.model &lt;- step(full.model, scope = list(lower = empty.model, upper = full.model), direction = &#39;backward&#39;, k = qchisq(0.03, 1, lower.tail=FALSE),trace = F) # summary(back.model) ## 3 vars. Age, servo slope ## Call: ## coxph(formula = Surv(censor, reason == 2) ~ age + servo + slope, ## data = hurricane) ## ## n= 770, number of events= 112 ## ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## age -1.51920 0.21889 0.17075 -8.897 &lt; 2e-16 *** ## servo 0.44075 1.55387 0.20412 2.159 0.0308 * ## slope -0.29120 0.74736 0.06677 -4.361 1.29e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## age 0.2189 4.5686 0.1566 0.3059 ## servo 1.5539 0.6436 1.0415 2.3182 ## slope 0.7474 1.3380 0.6557 0.8519 ## ## Concordance= 0.786 (se = 0.024 ) ## Likelihood ratio test= 132.9 on 3 df, p=&lt;2e-16 ## Wald test = 97.26 on 3 df, p=&lt;2e-16 ## Score (logrank) test = 94.6 on 3 df, p=&lt;2e-16 3.2 Linearity Assumption survminer::ggcoxfunctional(back.model,data=hurricane) Age and slope not linear, adjust them accordingly. 3.3 Time Dependency Assumption ## Binning hurricane &lt;- hurricane %&gt;% mutate(agebin = case_when(age&lt;7~0, age&lt;9~1, age&gt;=9~2)) %&gt;% mutate(slopebin = case_when(slope&lt;=3~0, slope&lt;=5~1, slope&gt;=10~2)) coxModel &lt;- coxph(Surv(censor,reason == 2) ~ servo + factor(slopebin) + factor(agebin), data = hurricane) ## Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, : Loglik converged ## before variable 3,5 ; coefficient may be infinite. coxZph &lt;- cox.zph(coxModel) coxZph ## chisq df p ## servo 0.279 1 0.60 ## factor(slopebin) 3.360 2 0.19 ## factor(agebin) 0.429 2 0.81 ## GLOBAL 3.857 5 0.57 ggcoxzph(coxZph, var=&#39;factor(slopebin)&#39;) Slope is definitely time dependent. Need to do tt(slope) in the hurricaneLong Model. 3.4 Model Building and Evaluation hurr_long = read_csv(&quot;~/hurrLong.csv&quot;) ## New names: ## Rows: 29661 Columns: 17 ## ── Column specification ## ──────────────────────────────────────────────────────────────────────── Delimiter: &quot;,&quot; dbl ## (17): ...1, id, backup, age, bridgecrane, servo, gear, trashrack, slope, elevation, surv... ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column ## types or set `show_col_types = FALSE` to quiet this message. ## • `` -&gt; `...1` hurr_long ## # A tibble: 29,661 × 17 ## ...1 id backup age bridgecrane servo gear trashrack slope elevation survive censor ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 6 0 0 0 1 3 2 1 48 ## 2 2 1 0 6 0 0 0 1 3 2 1 48 ## 3 3 1 0 6 0 0 0 1 3 2 1 48 ## 4 4 1 0 6 0 0 0 1 3 2 1 48 ## 5 5 1 0 6 0 0 0 1 3 2 1 48 ## 6 6 1 0 6 0 0 0 1 3 2 1 48 ## 7 7 1 0 6 0 0 0 1 3 2 1 48 ## 8 8 1 0 6 0 0 0 1 3 2 1 48 ## 9 9 1 0 6 0 0 0 1 3 2 1 48 ## 10 10 1 0 6 0 0 0 1 3 2 1 48 ## # ℹ 29,651 more rows ## # ℹ 5 more variables: reason &lt;dbl&gt;, reason2 &lt;dbl&gt;, hour &lt;dbl&gt;, pumpOn &lt;dbl&gt;, consecHour &lt;dbl&gt; hurr_long &lt;- hurr_long %&gt;% mutate(agebin = case_when(age&lt;6.4~0, age&lt;8.7~1, age&gt;=8.7~2)) %&gt;% mutate(slopebin = case_when(slope&lt;3~0, slope&gt;=3~1)) hurr_long &lt;- hurr_long %&gt;% dplyr::rename(stop = hour) hurr_long = hurr_long %&gt;% mutate(start = stop - 1) hurr_long ## # A tibble: 29,661 × 20 ## ...1 id backup age bridgecrane servo gear trashrack slope elevation survive censor ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 6 0 0 0 1 3 2 1 48 ## 2 2 1 0 6 0 0 0 1 3 2 1 48 ## 3 3 1 0 6 0 0 0 1 3 2 1 48 ## 4 4 1 0 6 0 0 0 1 3 2 1 48 ## 5 5 1 0 6 0 0 0 1 3 2 1 48 ## 6 6 1 0 6 0 0 0 1 3 2 1 48 ## 7 7 1 0 6 0 0 0 1 3 2 1 48 ## 8 8 1 0 6 0 0 0 1 3 2 1 48 ## 9 9 1 0 6 0 0 0 1 3 2 1 48 ## 10 10 1 0 6 0 0 0 1 3 2 1 48 ## # ℹ 29,651 more rows ## # ℹ 8 more variables: reason &lt;dbl&gt;, reason2 &lt;dbl&gt;, stop &lt;dbl&gt;, pumpOn &lt;dbl&gt;, consecHour &lt;dbl&gt;, ## # agebin &lt;dbl&gt;, slopebin &lt;dbl&gt;, start &lt;dbl&gt; mod2 = coxph(formula = Surv(start, stop, reason == 2) ~ factor(agebin) + factor(servo) + factor(slopebin) + factor(consecHour), data = hurr_long) summary(mod2) ## Call: ## coxph(formula = Surv(start, stop, reason == 2) ~ factor(agebin) + ## factor(servo) + factor(slopebin) + factor(consecHour), data = hurr_long) ## ## n= 29661, number of events= 112 ## ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## factor(agebin)1 -2.25868 0.10449 0.20035 -11.274 &lt; 2e-16 *** ## factor(agebin)2 -3.82652 0.02179 0.72557 -5.274 1.34e-07 *** ## factor(servo)1 0.30565 1.35751 0.20792 1.470 0.141558 ## factor(slopebin)1 -0.90564 0.40428 0.24239 -3.736 0.000187 *** ## factor(consecHour)1 0.11996 1.12745 0.20596 0.582 0.560278 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## factor(agebin)1 0.10449 9.5705 0.070556 0.15474 ## factor(agebin)2 0.02179 45.9024 0.005255 0.09032 ## factor(servo)1 1.35751 0.7366 0.903145 2.04045 ## factor(slopebin)1 0.40428 2.4735 0.251401 0.65014 ## factor(consecHour)1 1.12745 0.8870 0.752982 1.68814 ## ## Concordance= 0.793 (se = 0.024 ) ## Likelihood ratio test= 146.5 on 5 df, p=&lt;2e-16 ## Wald test = 151.6 on 5 df, p=&lt;2e-16 ## Score (logrank) test = 221.1 on 5 df, p=&lt;2e-16 AIC(mod2) ## [1] 1224.119 (exp(mod2$coefficients)-1) *100 ## factor(agebin)1 factor(agebin)2 factor(servo)1 factor(slopebin)1 ## -89.55120 -97.82146 35.75070 -59.57157 ## factor(consecHour)1 ## 12.74469 1/exp(mod2$coefficients) ## factor(agebin)1 factor(agebin)2 factor(servo)1 factor(slopebin)1 ## 9.5704783 45.9023676 0.7366445 2.4735067 ## factor(consecHour)1 ## 0.8869597 car::Anova(mod2) ## Analysis of Deviance Table (Type II tests) ## LR Chisq Df Pr(&gt;Chisq) ## factor(agebin) 131.472 2 &lt; 2.2e-16 *** ## factor(servo) 2.191 1 0.1389 ## factor(slopebin) 16.305 1 5.392e-05 *** ## factor(consecHour) 0.337 1 0.5613 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 library(party) library(partykit) hurr_long$y&lt;-ifelse(hurr_long$reason==2,1,0) hurr_long$y&lt;-ordered(hurr_long$y,levels=c(0,1),labels=&quot;No&quot;,&quot;Yes&quot;) model1&lt;-ctree(y~age,data=hurr_long) model1 ## ## Model formula: ## y ~ age ## ## Fitted party: ## [1] root ## | [2] age &lt;= 6.4: No1 (n = 5834, err = 1.1%) ## | [3] age &gt; 6.4 ## | | [4] age &lt;= 8.7: No1 (n = 20494, err = 0.2%) ## | | [5] age &gt; 8.7: No1 (n = 3333, err = 0.0%) ## ## Number of inner nodes: 2 ## Number of terminal nodes: 3 plot(model1) hurr_long$y&lt;-ifelse(hurr_long$reason==2,1,0) hurr_long$y&lt;-ordered(hurr_long$y,levels=c(0,1),labels=&quot;No&quot;,&quot;Yes&quot;) model1&lt;-ctree(y~slope,data=hurr_long) model1 ## ## Model formula: ## y ~ slope ## ## Fitted party: ## [1] root ## | [2] slope &lt;= 3: No1 (n = 21483, err = 0.5%) ## | [3] slope &gt; 3: No1 (n = 8178, err = 0.1%) ## ## Number of inner nodes: 1 ## Number of terminal nodes: 2 plot(model1) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
