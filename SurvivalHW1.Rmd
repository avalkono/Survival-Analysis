---
title: "Survival HW 1"
output: html_document
date: "2024-11-02"
---

# Survival Analysis Intro

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survival)
library(foreign)
library(ggplot2)
library(survminer)
library(rms)
library(flexsurv)
library(dplyr)
library(ciTools)
library(here)
library(visreg)
library(cmprsk)
library(reticulate)
library(aws.s3)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(stats)
library(UsingR)
```


```{r}
bucket_exists(
  bucket = "s3://survival2024/",
  region = "us-east-1"
)

files <- get_bucket_df(
  bucket = "s3://survival2024/",
  region = "us-east-1",
  max = 20000
) %>%
  as_tibble()

#Downloading files
save_object(
  object = "hurricane.csv", #Change
  bucket = "s3://survival2024/",
  region = "us-east-1",
  file = "hurricane" #Change
)

#You can now start Wrangling the data...
hurricane <- read.csv("hurricane") #Change
hurricane = hurricane %>% dplyr::mutate(Index = row_number())
```

1. Give the percentage of pumps within each failure type and percentage of pumps that did not fail.
```{r}
# Frequency table for the REASON variable
reason_counts <- table(hurricane$reason)
reason_counts

# Total number of pumps
total_pumps <- sum(reason_counts)

# Calculate percentages for each failure type
reason_percentages <- (reason_counts / total_pumps) * 100
reason_percentages
```
No failure: 41.03%
Reason 1: 14.94%
Reason 2: 14.55%
Reason 3: 14.42%
Reason 4: 15.06%


2. Give the average time until failure for each failure type.  Are means a good measure for length of survival?  Discuss why or why not.
```{r}
# Calculate mean failure time for each failure type
average_failure_time <- aggregate(hurricane$hour, by = list(hurricane$reason), FUN = mean, na.rm = TRUE)

# Rename columns for clarity
colnames(average_failure_time) <- c("Failure_Type", "Average_Time_Until_Failure")

# Print the results
average_failure_time
```
Reason 1: 26.44 hr
Reason 2: 41.04 hr
Reason 3: 38.83 hr
Reason 4: 21.94 hr
Means are not a good measure of length of survival because censored values included in the mean can impact the mean survival time. Median is a better measure.


3. Create and upload the survival probability across time for pumps broken down by failure type overlaid into one graph.
```{r}
# Assuming the SURVIVE variable is coded as 1 for failed and 0 for not failed
surv_object <- Surv(time = hurricane$hour, event = hurricane$survive == 0)

# Fit the Kaplan-Meier survival model, stratified by failure type (REASON)
km_fit <- survfit(surv_object ~ hurricane$reason, data = hurricane)

# Plot survival curves with ggplot2 styling for readability
surv_plot <- ggsurvplot(
  km_fit, 
  data = hurricane,
  conf.int = TRUE,
  legend.title = "Failure Type",
  legend.labs = c("No Failure", "Flood", "Motor", "Surge", "Jammed"),
  xlab = "Time (hours)",
  ylab = "Survival Probability",
  title = "Survival Probability Across Time by Failure Type",
  ggtheme = theme_minimal()
)

surv_plot
```

4. Create and upload the graph of conditional failure probabilities across time for pumps broken down by failure type overlaid into one graph.
```{r}
km_fit <- survfit(surv_object ~ hurricane$reason, data = hurricane)
h = km_fit$n.event/km_fit$n.risk
index.h=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0
index.h[(km_fit$time)+1]=h #Because of 0
haz.plot=data.frame(cbind(seq(0,max(hurricane$hour)), index.h))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()

ggsurvplot(km_fit, data = hurricane, fun = "cumhaz", conf.int = TRUE, xlab = "Time (hour)", ylab = "Cumulative Hazard", title = "Conditional Failure Probabilities",   legend.title = "Failure Type",
  legend.labs = c("No Failure", "Flood", "Motor", "Surge", "Jammed"))
```

```{r}
surv_object <- Surv(time = filter(hurricane, reason==1)$hour, event = filter(hurricane, reason==1)$survive == 0)
km_fit <- survfit(surv_object ~ 1, data = filter(hurricane, reason==1))
h1 = km_fit$n.event/km_fit$n.risk
index.h1=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0
index.h1[(km_fit$time)+1]=h1 #Because of 0
haz.plot1=data.frame(cbind(seq(0,max(hurricane$hour)), index.h1))
haz.plot1$Reason1 = 1

surv_object <- Surv(time = filter(hurricane, reason==2)$hour, event = filter(hurricane, reason==2)$survive == 0)
km_fit <- survfit(surv_object ~ 1, data = filter(hurricane, reason==2))
h2 = km_fit$n.event/km_fit$n.risk
index.h2=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0
index.h2[(km_fit$time)+1]=h2 #Because of 0
haz.plot2=data.frame(cbind(seq(0,max(hurricane$hour)), index.h2))
haz.plot2$Reason2 = 2

surv_object <- Surv(time = filter(hurricane, reason==3)$hour, event = filter(hurricane, reason==3)$survive == 0)
km_fit <- survfit(surv_object ~ 1, data = filter(hurricane, reason==3))
h3 = km_fit$n.event/km_fit$n.risk
index.h3=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0
index.h3[(km_fit$time)+1]=h3 #Because of 0
haz.plot3=data.frame(cbind(seq(0,max(hurricane$hour)), index.h3))
haz.plot3$Reason3 = 3

surv_object <- Surv(time = filter(hurricane, reason==4)$hour, event = filter(hurricane, reason==4)$survive == 0)
km_fit <- survfit(surv_object ~ 1, data = filter(hurricane, reason==4))
h4 = km_fit$n.event/km_fit$n.risk
index.h4=rep(0,length=(max(hurricane$hour)+1)) #Need to add 0
index.h4[(km_fit$time)+1]=h4 #Because of 0
haz.plot4=data.frame(cbind(seq(0,max(hurricane$hour)), index.h4))
haz.plot4$Reason4 = 4

haz.plot.all = cbind(haz.plot1, haz.plot2, haz.plot3, haz.plot4)
```


```{r}
haz.plot.all2 = haz.plot.all %>% dplyr::select(1, index.h1, index.h2, index.h3, index.h4)
```


```{r}
ggplot(haz.plot.all2, aes(x=V1)) +
    geom_line(aes(y = index.h1, color='Flood')) +
    geom_line(aes(y = index.h2, color='Motor')) +
    geom_line(aes(y = index.h3, color = 'Surge')) +
    geom_line(aes(y = index.h4, color= 'Jammed')) +
    labs(
        title = "Hazard Rates by Failure Type",
        x = "Hours",
        y = "Hazard",
        color = "Failure Type"
    ) + scale_color_manual(
        values = c('Flood' = 'blue', 'Motor' = 'red', 'Surge' = 'orange', 'Jammed' = 'green'),
        labels = c("Flood", "Motor", "Surge", "Jammed")) +
    theme_minimal() +
    scale_x_continuous(breaks = seq(0, 48, by = 6))
```






5. Provide a statistical test to see if the major types of failure have similar survival probabilities across time (include null and alternative hypotheses, test statistic, p-value and conclusion).
```{r}
# Log-Rank Test 
surv_object <- Surv(time = hurricane$hour, event = hurricane$survive == 0)
survdiff(surv_object ~ hurricane$reason, data=hurricane,rho=0)
```
Log-Rank Test:

H0: No significant difference in survival probabilities.

Ha: Significant difference in survival probabilities.

Test statistic: 1120 on 4 degrees of freedom

p-value: <2e-16

Conclusion: Reject the null -> There is a significant difference in survival probabilities over time across failure types.





# Accelerated Failure Time Model

##Model Building
```{r}
hurricane = hurricane %>% mutate(flood = ifelse(reason==1, 1, 0))
```

```{r}
hurr.aft.w <- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "weibull")

plot(hurr.aft.w, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Weibull Distribution")

hurr.aft.e <- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "exp")

plot(hurr.aft.e, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Exponential Distribution")

hurr.aft.g <- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "gamma")

plot(hurr.aft.g, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Gamma Distribution")

hurr.aft.ll <- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "llogis")

plot(hurr.aft.ll, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Log-Logistic Distribution")

hurr.aft.ln <- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "lognormal")

plot(hurr.aft.ln, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Log-Normal Distribution")
```

##Goodness-of-Fit Tests 
```{r}

like.e = flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "exp")$loglik
like.w <- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "weibull")$loglik
like.ln <- flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "lnorm")$loglik
like.g = flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "gamma")$loglik
like.ll = flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "llogis")$loglik
like.f = flexsurvreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "genf")$loglik


pval.e.g = pchisq((-2*(like.e-like.g)), 2,lower.tail=F)
pval.w.g = pchisq((-2*(like.w-like.g)), 1,lower.tail=F)
pval.ln.g = pchisq((-2*(like.ln-like.g)), 1,lower.tail=F)
##pval.g.f = pchisq((-2*(like.g-like.f)), 1,lower.tail=F)


Tests = c('Exp vs. Gam', 'Wei vs. Gam', 'LogN vs. Gam')
P_values = c(pval.e.g, pval.w.g, pval.ln.g)
cbind(Tests, P_values)
```
No difference between Weibull and Gam -> use Weibull

##Variable Selection
```{r}
full.model <- survreg(Surv(hour, flood) ~ backup + age + bridgecrane + servo + gear + trashrack + slope + elevation, data = hurricane, dist = "weibull")
empty.model <- survreg(Surv(hour, flood) ~ 1, data = hurricane, dist = "weibull")
back.model <- step(full.model,
                   scope = list(lower = empty.model,
                               upper = full.model),
                  direction = 'backward', k = qchisq(0.03, 1, lower.tail=FALSE))
```

```{r}
hurr.aft = survreg(Surv(hour, flood) ~ backup + servo + slope, data = hurricane, dist = "weibull")
summary(hurr.aft)
```

```{r}
survprob.75.50.25 = predict(hurr.aft, type = "quantile", se.fit = TRUE,p = c(0.25, 0.5, 0.75))
head(survprob.75.50.25$fit)
```

```{r}
exp(coef(hurr.aft)) - 1
```


##Variable Impact
```{r}
hurricane = hurricane %>% dplyr::mutate(pump = row_number())
#Servo impact
survprob.actual = 1 - psurvreg(hurricane$hour,
      mean = predict(hurr.aft, type = "lp"),
      scale = hurr.aft$scale, distribution = hurr.aft$dist)

new_time = qsurvreg(1 - survprob.actual,
mean = predict(hurr.aft, type = "lp") +
coef(hurr.aft)['servo'],
scale = hurr.aft$scale,
distribution = hurr.aft$dist)

hurricane$new_time = new_time
hurricane$diff = hurricane$new_time - hurricane$hour
impact.servo=data.frame(hurricane$hour, hurricane$new_time, hurricane$diff, hurricane$flood, hurricane$servo, hurricane$pump)
colnames(impact.servo)=c("O.hour","N.hour","Diff_servo","flood","servo", "pump")
impact.servo=subset(impact.servo,flood==1 & servo==0)
impact.servo %>% arrange(desc(Diff_servo)) %>% filter(O.hour <48 & N.hour >48)
testing = impact.servo %>% arrange(desc(Diff_servo)) %>% filter(N.hour < 49 & N.hour >33)
testing
```


```{r}
#Backup impact
survprob.actual = 1 - psurvreg(hurricane$hour,
      mean = predict(hurr.aft, type = "lp"),
      scale = hurr.aft$scale, distribution = hurr.aft$dist)
head(survprob.actual, n = 10)

new_time = qsurvreg(1 - survprob.actual,
mean = predict(hurr.aft, type = "lp") +
coef(hurr.aft)['backup'],
scale = hurr.aft$scale,
distribution = hurr.aft$dist)

hurricane$new_time = new_time
hurricane$diff = hurricane$new_time - hurricane$hour
impact.backup=data.frame(hurricane$hour, hurricane$new_time, hurricane$diff, hurricane$flood, hurricane$backup, hurricane$pump)
colnames(impact.backup)=c("O.hour","N.hour","Diff_backup","flood","backup", "pump")
impact.backup=subset(impact.backup,flood==1 & backup==0)
impact.backup %>% arrange(desc(Diff_backup)) %>% filter(N.hour >48)
testing2 = impact.backup %>% arrange(desc(Diff_backup)) %>% filter(N.hour < 49  & N.hour >33)
testing2
```

```{r}
list1 <- testing$pump
list2 <- testing2$pump

# Find items in list1 that are not in list2
not_in_list2 <- list1[list1 %in% list2]
print(not_in_list2)
```

367, 369, 376, 319, 321 all inc more with Servo

```{r}
upgrades = merge(impact.servo, impact.backup, by="pump", all=TRUE) %>% dplyr::select(Diff_servo, Diff_backup, pump) 
upgrades[is.na(upgrades)] <- 0
upgrades = upgrades %>% mutate(servo_impact = 150000/Diff_servo,
                               backup_impact = 100000/Diff_backup,
                               better = ifelse(backup_impact > servo_impact, 1, 0))
upgrades %>% arrange(desc(Diff_servo))
upgrades %>% arrange(desc(Diff_backup))
```




